# ğŸ¤– Code Documentation Assistant

A sophisticated RAG-based system for analyzing, documenting, and understanding codebases using AI. Built with FastAPI, LangChain, and Google Gemini.

## ğŸŒŸ Features

- **Multi-Language Code Analysis**: Support for Python, JavaScript, TypeScript, Java, Go, Rust, C++, C
- **AST-Based Parsing**: Deep code understanding using Tree-sitter parsers
- **Intelligent Code Chunking**: Semantic-aware chunking with 5 different strategies
- **Multi-Model Embeddings**: Google Embedding, CodeBERT, Sentence Transformers
- **Vector Database**: ChromaDB integration with persistent storage
- **Semantic Code Search**: Find similar code patterns and functions
- **AI-Powered Documentation**: Automatic generation of comprehensive documentation
- **API Discovery**: Automatically detect and document API endpoints
- **Code Quality Analysis**: Complexity metrics and improvement suggestions
- **Git Integration**: Analyze repositories and track changes
- **Real-time Processing**: Fast, concurrent file analysis (133+ embeddings/sec)

## ğŸ—ï¸ Architecture

```
Code Documentation Assistant
â”œâ”€â”€ Core RAG System (Google Gemini + ChromaDB)
â”‚   â”œâ”€â”€ AST Parser (Tree-sitter) âœ…
â”‚   â”œâ”€â”€ Intelligent Chunker âœ…
â”‚   â”œâ”€â”€ Multi-Model Embedder âœ…
â”‚   â””â”€â”€ Vector Store (ChromaDB) âœ…
â”œâ”€â”€ Code Analyzer (Multi-language)
â”œâ”€â”€ API Layer (FastAPI)
â””â”€â”€ Frontend (Coming Soon)
```

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
git clone <your-repo-url>
cd ScalableRAGsystem
```

### 2. Create Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment

```bash
# Run the setup script
python setup_environment.py
```

This will:
- Create a `.env` file from the template
- Check all dependencies
- Validate your API keys
- Test connections

### 5. Add Your API Keys

Edit the `.env` file and add your actual API keys:

```bash
# Required
GOOGLE_API_KEY=your_actual_google_api_key_here

# Optional
OPENAI_API_KEY=your_openai_key_here
PINECONE_API_KEY=your_pinecone_key_here
```

**Get API Keys:**
- ğŸ”‘ **Google Gemini**: [Get API Key](https://makersuite.google.com/app/apikey)
- ğŸ”‘ **OpenAI** (Optional): [Get API Key](https://platform.openai.com/api-keys)
- ğŸ”‘ **Pinecone** (Optional): [Get API Key](https://app.pinecone.io/)

### 6. Run the Application

```bash
# Test the RAG pipeline
python test_complete_rag.py

# Test chunking and embeddings
python test_chunking.py

# Start the server (when API is ready)
uvicorn main:app --reload
```

Visit `http://localhost:8000/docs` for the interactive API documentation.

## ğŸ“ Project Structure

```
ScalableRAGsystem/
â”œâ”€â”€ code_assistant/              # Main package
â”‚   â”œâ”€â”€ core/                   # Core functionality âœ…
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â”‚   â”œâ”€â”€ exceptions.py      # Custom exceptions
â”‚   â”‚   â”œâ”€â”€ types.py           # Data models & types
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ parsers/               # Code parsers (AST, Tree-sitter) âœ…
â”‚   â”‚   â”œâ”€â”€ base_parser.py     # Abstract parser base
â”‚   â”‚   â”œâ”€â”€ tree_sitter_parser.py # Tree-sitter implementation
â”‚   â”‚   â”œâ”€â”€ python_parser.py   # Python-specific enhancements
â”‚   â”‚   â””â”€â”€ parser_factory.py  # Parser factory
â”‚   â”œâ”€â”€ embeddings/            # Embedding systems âœ…
â”‚   â”‚   â”œâ”€â”€ chunker.py         # Intelligent code chunking
â”‚   â”‚   â”œâ”€â”€ embedder.py        # Multi-model embedding generation
â”‚   â”‚   â””â”€â”€ vector_store.py    # ChromaDB vector storage
â”‚   â”œâ”€â”€ analyzers/             # Code analysis engines
â”‚   â”œâ”€â”€ api/                   # API endpoints
â”‚   â”œâ”€â”€ models/                # Database models
â”‚   â”œâ”€â”€ utils/                 # Utilities
â”‚   â””â”€â”€ tests/                 # Test suite
â”œâ”€â”€ sample_repos/              # Test data âœ…
â”‚   â””â”€â”€ sample_python_project/ # Sample Python code
â”œâ”€â”€ requirements.txt           # Dependencies (77 packages)
â”œâ”€â”€ main.py                    # Original RAG system
â”œâ”€â”€ test_complete_rag.py       # Complete pipeline test âœ…
â”œâ”€â”€ test_chunking.py           # Chunking & embedding test âœ…
â”œâ”€â”€ setup_environment.py       # Environment setup script
â”œâ”€â”€ env_template.txt           # Environment template
â””â”€â”€ README.md                  # This file
```

## ğŸ”§ Configuration

The system uses environment variables for configuration. Key settings:

```bash
# API Keys
GOOGLE_API_KEY=required
OPENAI_API_KEY=optional
PINECONE_API_KEY=optional

# Application
DEBUG=false
DEV_MODE=true
LOG_LEVEL=INFO

# Database
DATABASE_URL=sqlite:///./code_assistant.db
REDIS_URL=redis://localhost:6379

# Performance
MAX_CONCURRENT_FILES=10
CACHE_TTL_HOURS=24
```

## ğŸ§ª Testing

Test with the sample Python project:

```bash
# Test the complete RAG pipeline
python test_complete_rag.py

# Test individual components
python test_chunking.py

# The system includes sample code in sample_repos/
# This demonstrates various Python constructs:
# - Classes and inheritance
# - Functions with type hints
# - Decorators
# - Documentation strings
# - Error handling
```

## ğŸ“Š Current Status

### âœ… Phase 1 Complete: Foundation & Planning
- [x] Project architecture design
- [x] Enhanced requirements and dependencies (77 packages)
- [x] Configuration management system
- [x] Type definitions and data models (15+ Pydantic models)
- [x] Exception handling framework
- [x] Sample test data
- [x] Environment setup automation

### âœ… Phase 2 Complete: Enhanced RAG Features
- [x] **AST Parsing Engine**: Tree-sitter multi-language parser (8 languages)
  - Multi-language support (Python, JavaScript, TypeScript, Java, Go, Rust, C++, C)
  - Complexity analysis and type hint extraction
  - Design pattern detection and inheritance analysis
  - Factory pattern for parser creation
- [x] **Intelligent Code Chunking**: 5 chunking strategies
  - Function-based, Class-based, Semantic blocks, Sliding window, Hybrid
  - Context-aware chunking with metadata preservation
  - Smart merging and docstring extraction
  - 70 chunks generated from 2 sample files
- [x] **Multi-Model Embeddings**: 3 embedding models supported
  - Google Text Embedding (768D), Sentence Transformers (384D), CodeBERT (768D)
  - Context-aware embedding with metadata integration
  - Batch processing (133+ embeddings/sec)
  - Async processing and caching
- [x] **Vector Database**: ChromaDB integration
  - Persistent storage with metadata filtering
  - Semantic search with similarity thresholds
  - Language and element type filtering
  - Production-ready with error handling

<<<<<<< HEAD
### âœ… Phase 3 Complete: Code Analysis Engine
- [x] Advanced complexity analysis
- [x] Dependency tracking and relationship mapping
- [x] Code pattern detection and best practices
- [x] Security vulnerability scanning
- [x] Performance optimization suggestions

### âœ… Phase 4 Complete: API Layer Implementation
- [x] Core API endpoints (/analyze, /search, /document, /metrics)
- [x] Request/Response models with Pydantic validation
- [x] Background tasks for async processing
- [x] Auto-generated OpenAPI documentation
- [x] Health check and status endpoints

### âœ… Phase 5 Complete: Frontend Development
- [x] Modern Next.js 14+ with TypeScript
- [x] Interactive dashboards for all features
- [x] Real-time code analysis interface
- [x] Semantic search with syntax highlighting
- [x] Documentation generator with live preview
- [x] Metrics visualization with charts
- [x] Responsive design with Tailwind CSS
- [x] API integration with React Query

### ğŸ”® Future Phases
- [ ] Production deployment
- [ ] Authentication & rate limiting
- [ ] Websocket progress updates

## ğŸ¯ System Performance

**Current Benchmarks:**
- **Parsing**: 49+ code elements from complex Python files
- **Chunking**: 70 chunks from 2 files with rich metadata
- **Embedding**: 133+ embeddings/second
- **Search**: Sub-second semantic search responses
- **Languages**: 8 programming languages supported
- **File Extensions**: 19+ file extensions recognized

## ğŸ¯ System Performance

**Current Benchmarks:**
- **Parsing**: 49+ code elements from complex Python files
- **Chunking**: 70 chunks from 2 files with rich metadata
- **Embedding**: 133+ embeddings/second
- **Search**: Sub-second semantic search responses
- **Languages**: 8 programming languages supported
- **File Extensions**: 19+ file extensions recognized

## ğŸ› ï¸ Development

### Adding New Languages

1. Add language to `LanguageType` enum in `core/types.py`
2. Add file extensions to parser factory
3. Install Tree-sitter grammar: `pip install tree-sitter-<language>`
4. Implement language-specific parser enhancements

### Running Tests

```bash
# Test complete RAG pipeline
python test_complete_rag.py

# Test chunking and embeddings
python test_chunking.py

# Install test dependencies
pip install pytest pytest-cov

# Run tests (when test suite is complete)
pytest code_assistant/tests/

# With coverage
pytest --cov=code_assistant
```

### Code Quality

```bash
# Format code
black code_assistant/

# Type checking
mypy code_assistant/

# Linting
flake8 code_assistant/
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Troubleshooting

### Common Issues

**1. Import Errors**
```bash
# Ensure virtual environment is activated
source .venv/bin/activate
pip install -r requirements.txt
```

**2. API Key Issues**
```bash
# Run the setup script to validate
python setup_environment.py
```

**3. Tree-sitter Installation Issues**
```bash
# Reinstall tree-sitter parsers
pip uninstall tree-sitter tree-sitter-python tree-sitter-javascript
pip install tree-sitter tree-sitter-python tree-sitter-javascript tree-sitter-typescript
```

**4. ChromaDB Issues**
```bash
# Remove and recreate vector database
rm -rf chroma_db/ test_chroma_db/
python test_complete_rag.py
```

**5. Embedding Model Download**
```bash
# The first run downloads models automatically
# Ensure stable internet connection for model downloads
```

### Getting Help

- ğŸ“– Check the test files for usage examples
- ğŸ› Report issues on GitHub
- ğŸ’¬ Join our community discussions

## ğŸ¯ Next Steps

1. **Start Phase 3**: Implement advanced code analysis engine
2. **Add More Languages**: Extend Tree-sitter parser support
3. **Build API Layer**: Create FastAPI endpoints
4. **Build Frontend**: Create a web interface
5. **Deploy**: Set up production deployment
6. **Scale**: Add distributed processing capabilities

## ğŸ”¬ Technical Highlights

**Advanced Features Implemented:**
- **AST-Aware Chunking**: Preserves code semantics and structure
- **Multi-Modal Embeddings**: Combines code content with metadata context
- **Production-Ready**: Error handling, retry logic, caching, async processing
- **Extensible Architecture**: Factory patterns and strategy patterns for flexibility
- **Type Safety**: Comprehensive Pydantic models with validation
- **Performance Optimized**: Batch processing and concurrent execution

---

**Happy Coding! ğŸš€** Built with â¤ï¸ for developers who love clean, well-documented code. 